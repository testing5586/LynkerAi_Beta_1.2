"""
Multi-Model Dispatcher é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨å„ç§åœºæ™¯ä¸­ä½¿ç”¨æ™ºèƒ½æ¨¡å‹é€‰æ‹©ç³»ç»Ÿ
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from multi_model_dispatcher import get_model_for_user, get_api_key_for_user, load_ai_rules

def example_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨"""
    print("=== ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨ ===\n")
    
    user_id = 2
    model = get_model_for_user(user_id)
    api_key = get_api_key_for_user(user_id)
    
    print(f"ç”¨æˆ· {user_id} ä½¿ç”¨æ¨¡å‹: {model}")
    print(f"API Key å‰ç¼€: {api_key[:20] if api_key else 'None'}...\n")

def example_2_openai_integration():
    """ç¤ºä¾‹ 2: é›†æˆåˆ° OpenAI è°ƒç”¨"""
    print("=== ç¤ºä¾‹ 2: OpenAI é›†æˆ ===\n")
    
    print("ä»£ç ç¤ºä¾‹:")
    print("""
    import openai
    from multi_model_dispatcher import get_model_for_user, get_api_key_for_user
    
    def call_ai_for_user(user_id: int, prompt: str):
        model = get_model_for_user(user_id)
        api_key = get_api_key_for_user(user_id)
        
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    """)
    print("ğŸ’¡ æç¤º: è¿™æ ·å¯ä»¥è‡ªåŠ¨ä¸ºæ¯ä¸ªç”¨æˆ·é€‰æ‹©åˆé€‚çš„æ¨¡å‹\n")

def example_3_batch_processing():
    """ç¤ºä¾‹ 3: æ‰¹é‡å¤„ç†å¤šä¸ªç”¨æˆ·"""
    print("=== ç¤ºä¾‹ 3: æ‰¹é‡å¤„ç† ===\n")
    
    user_ids = [1, 2, 3, 4, 5]
    
    print("ç”¨æˆ·æ¨¡å‹åˆ†é…:")
    for uid in user_ids:
        model = get_model_for_user(uid)
        print(f"  ç”¨æˆ· {uid} â†’ {model}")
    
    print()

def example_4_config_management():
    """ç¤ºä¾‹ 4: é…ç½®ç®¡ç†"""
    print("=== ç¤ºä¾‹ 4: é…ç½®ç®¡ç† ===\n")
    
    rules = load_ai_rules()
    
    print("å½“å‰ AI è§„åˆ™é…ç½®:")
    for key, value in rules.items():
        print(f"  {key}: {value}")
    
    print("\nğŸ’¡ æç¤º: å¯ä»¥åœ¨ Supabase ai_rules è¡¨ä¸­æ›´æ–°è¿™äº›é…ç½®")
    print("   æ›´æ–°åæ— éœ€é‡å¯ç³»ç»Ÿå³å¯ç”Ÿæ•ˆï¼\n")

def example_5_master_ai_integration():
    """ç¤ºä¾‹ 5: é›†æˆåˆ° Master AI Reasoner"""
    print("=== ç¤ºä¾‹ 5: Master AI Reasoner é›†æˆ ===\n")
    
    def master_ai_reason_user(user_id: int):
        """ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹ä¸ºç”¨æˆ·æ¨ç†"""
        model = get_model_for_user(user_id)
        api_key = get_api_key_for_user(user_id)
        
        print(f"ğŸ§  Master AI æ¨ç†å¼•æ“å¯åŠ¨...")
        print(f"   ç”¨æˆ·: {user_id}")
        print(f"   æ¨¡å‹: {model}")
        print(f"   API Key: {'LYNKER_MASTER_KEY' if 'LYNKER' in str(api_key) else 'User Key'}")
        print(f"   çŠ¶æ€: å°±ç»ª")
        
    master_ai_reason_user(2)
    print()

def example_6_cost_optimization():
    """ç¤ºä¾‹ 6: æˆæœ¬ä¼˜åŒ–å»ºè®®"""
    print("=== ç¤ºä¾‹ 6: æˆæœ¬ä¼˜åŒ–å»ºè®® ===\n")
    
    print("ğŸ’° æ¨¡å‹æˆæœ¬å¯¹æ¯”:")
    print("  gpt-4o-mini:  $0.15 / 1M tokens (è¾“å…¥)")
    print("  gpt-4-turbo:  $10.00 / 1M tokens (è¾“å…¥)")
    print()
    print("ğŸ“Š å»ºè®®ç­–ç•¥:")
    print("  âœ… Free ç”¨æˆ· â†’ gpt-4o-mini (ä½æˆæœ¬)")
    print("  âœ… Pro ç”¨æˆ· â†’ gpt-4-turbo (é«˜è´¨é‡)")
    print("  âœ… Admin â†’ gpt-4-turbo (æœ€ä½³æ€§èƒ½)")
    print()
    print("ğŸ’¡ ä¼˜åŒ–æŠ€å·§:")
    print("  1. ä½¿ç”¨ max_tokens é™åˆ¶å“åº”é•¿åº¦")
    print("  2. ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ")
    print("  3. æ‰¹é‡å¤„ç†é™ä½ API è°ƒç”¨æ¬¡æ•°")
    print()

if __name__ == "__main__":
    print("\n" + "="*60)
    print("  Multi-Model Dispatcher é›†æˆç¤ºä¾‹")
    print("="*60 + "\n")
    
    example_1_basic_usage()
    example_2_openai_integration()
    example_3_batch_processing()
    example_4_config_management()
    example_5_master_ai_integration()
    example_6_cost_optimization()
    
    print("="*60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("ğŸ“š æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹: MULTI_MODEL_DISPATCHER_GUIDE.md")
    print("="*60 + "\n")
