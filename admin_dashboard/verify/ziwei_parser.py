"""
ç´«å¾®æ–—æ•°ä¸¥æ ¼è§£æå™¨ v1.0
ä»…ä½¿ç”¨è§„åˆ™/æ­£åˆ™æå–ï¼Œä¸åšä»»ä½• AI æ¨ç†æˆ–è¡¥å…¨
æ”¯æŒï¼š
1. æ–‡å¢¨å¤©æœº AI åˆ†æç‰ˆ JSON æ–‡ä»¶
2. æ™®é€šæ–‡æœ¬æ ¼å¼å‘½ç›˜ï¼ˆå°½åŠ›æå–ï¼‰
3. TXT è¡¥ä¸æ¨¡å—ï¼šæ™ºèƒ½è§£ææ–‡å¢¨å¤©æœºå¯¼å‡ºçš„ .txt æ–‡ä»¶
"""
import json
import re
from typing import Dict, Any, List

# âœ¨ å¯¼å…¥ TXT è¡¥ä¸æ¨¡å—
try:
    from .ziwei_txt_patch import parse_wenmo_txt_to_json
    TXT_PATCH_AVAILABLE = True
    print("[Ziwei Parser] âœ… TXT è¡¥ä¸æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    print(f"[Ziwei Parser] âš ï¸ TXT è¡¥ä¸æ¨¡å—æœªæ‰¾åˆ°: {e}")
    TXT_PATCH_AVAILABLE = False

# 12 å®«ä½æ ‡å‡†åç§°
PALACES = ["å‘½å®«", "å…„å¼Ÿå®«", "å¤«å¦»å®«", "å­å¥³å®«", "è´¢å¸›å®«", "ç–¾å„å®«", 
           "è¿ç§»å®«", "ä»†å½¹å®«", "å®˜ç¦„å®«", "ç”°å®…å®«", "ç¦å¾·å®«", "çˆ¶æ¯å®«"]


def _clean(s: str) -> str:
    """æ¸…ç†å­—ç¬¦ä¸²ï¼šå»é™¤å¤šä½™ç©ºç™½"""
    return re.sub(r'\s+', ' ', s or '').strip()


def _empty_v11() -> Dict[str, Any]:
    """è¿”å›ç©ºçš„ ZiweiAI_v1.1 ç»“æ„"""
    return {
        "meta": {
            "parser_version": "ZiweiAI_v1.1",
            "source": "æ–‡å¢¨å¤©æœº",
            "system": "LynkerAI ZiweiAI",
        },
        "basic_info": {
            "æ€§åˆ«": "",
            "é˜³å†æ—¥æœŸ": "",
            "é˜´å†æ—¥æœŸ": "",
            "çœŸå¤ªé˜³æ—¶": "",
            "å‘½ä¸»": "",
            "èº«ä¸»": "",
            "å‘½å±€": "",
        },
        "star_map": {p: [] for p in PALACES},
        "transformations": {
            "ç”Ÿå¹´å››åŒ–": {"ç¦„": "", "æƒ": "", "ç§‘": "", "å¿Œ": ""},
            "æµå¹´å››åŒ–": {"ç¦„": "", "æƒ": "", "ç§‘": "", "å¿Œ": ""},
        },
        "tags": {"æ ¼å±€": [], "æ€§æ ¼": [], "ä¼˜åŠ¿": [], "é£é™©å› å­": []},
        "success": True
    }


def parse_wenmo_ai_json(obj: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä¿®æ­£ç‰ˆ v1.3
    è‡ªåŠ¨å…¼å®¹ï¼š
    - æ–‡å¢¨AIæ ‡å‡†JSONï¼ˆå« basic_info, star_mapï¼‰
    - æ‰å¹³JSONï¼ˆæ—§æ ¼å¼ï¼‰
    - ç¹ç®€ä½“å®«ä½åï¼ˆè²¡å¸›å®®â†’è´¢å¸›å®«ï¼‰
    """
    import copy
    
    # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¾“å…¥ç»“æ„
    print("[Ziwei Parser Debug] åŸå§‹ JSON é¡¶å±‚å­—æ®µ:", list(obj.keys()))
    try:
        sample = json.dumps(obj, ensure_ascii=False)[:500]
        print(f"[Ziwei Parser Debug] æ ·æœ¬å†…å®¹å‰500å­—ç¬¦: {sample}")
    except Exception as e:
        print(f"[Ziwei Parser Debug] æ— æ³•æ‰“å° JSON å†…å®¹: {e}")
    
    # ğŸ§© Step 1. å¦‚æœæ˜¯æ–‡å¢¨AIæ ‡å‡†æ ¼å¼ï¼ˆå« basic_infoï¼‰
    if "basic_info" in obj and "star_map" in obj:
        print("[Ziwei Parser Debug] ğŸ§  æ£€æµ‹åˆ°æ ‡å‡†æ–‡å¢¨AI JSONæ ¼å¼ï¼Œç›´æ¥å¤åˆ¶å­—æ®µ")
        bi = copy.deepcopy(obj["basic_info"])
        sm = copy.deepcopy(obj["star_map"])
        tx = obj.get("transformations", {})

        # ğŸˆ¶ ç¹ç®€ä½“å®«åè‡ªåŠ¨æ›¿æ¢
        mapping = {
            "è²¡å¸›å®®": "è´¢å¸›å®«", "å…„å¼Ÿå®®": "å…„å¼Ÿå®«", "å‘½å®®": "å‘½å®«",
            "å¤«å¦»å®®": "å¤«å¦»å®«", "å­å¥³å®®": "å­å¥³å®«", "çˆ¶æ¯å®®": "çˆ¶æ¯å®«",
            "ç”°å®…å®®": "ç”°å®…å®«", "å®˜ç¥¿å®®": "å®˜ç¦„å®«", "äº¤å‹å®®": "äº¤å‹å®«",
            "ç–¾å„å®®": "ç–¾å„å®«", "é·ç§»å®®": "è¿ç§»å®«", "ç¦å¾·å®®": "ç¦å¾·å®«"
        }

        # ğŸˆ¶ ç¹ç®€ä½“å®«åæ›¿æ¢ + ä¿æŒå­—å…¸æ ¼å¼
        new_sm = {}
        for k, v in sm.items():
            key_simplified = mapping.get(k, k)
            new_sm[key_simplified] = v  # ä¿æŒåŸå§‹æ ¼å¼ï¼ˆå­—å…¸æˆ–åˆ—è¡¨ï¼‰
        
        sm = new_sm
        
        # ğŸ” è¾“å‡ºç¡®è®¤æ—¥å¿—
        print("[Ziwei Parser Debug] âœ… æ ‡å‡†æ ¼å¼æ•°æ®å·²å¤åˆ¶ï¼ˆä¿æŒå­—å…¸æ ¼å¼ï¼‰")
        print(f"[Ziwei Parser Debug] åŸºæœ¬ä¿¡æ¯: {bi}")
        print(f"[Ziwei Parser Debug] å®«ä½æ•°é‡: {len([p for p in sm.values() if p])}")
        sample_palace = sm.get('å‘½å®«') or sm.get('å‘½å®®')
        if sample_palace:
            print(f"[Ziwei Parser Debug] å‘½å®«ç¤ºä¾‹: {sample_palace}")
        
        out = _empty_v11()
        out["meta"] = obj.get("meta", {})
        out["basic_info"] = bi
        out["star_map"] = sm
        out["transformations"] = tx
        out["tags"] = obj.get("tags", {"æ ¼å±€": [], "æ€§æ ¼": [], "ä¼˜åŠ¿": [], "é£é™©å› å­": []})
        
        return out

    # ğŸ§© Step 2. è‹¥æ˜¯æ‰å¹³ç»“æ„ï¼Œæ—§é€»è¾‘ç»§ç»­å…¼å®¹
    print("[Ziwei Parser Debug] âš™ï¸ æ£€æµ‹åˆ°æ‰å¹³ç»“æ„ï¼Œå›é€€æ—§é€»è¾‘è§£æ")
    
    out = _empty_v11()
    bi = out["basic_info"]
    
    for key in ["æ€§åˆ«", "gender", "æ€§åˆ¥"]:
        v = obj.get(key)
        if v:
            bi["æ€§åˆ«"] = _clean(str(v))
            break
    
    for key in ["å‘½ä¸»", "å‘½ä¸»æ˜Ÿ"]:
        v = obj.get(key)
        if v:
            bi["å‘½ä¸»"] = _clean(str(v))
            break
    
    for key in ["èº«ä¸»", "èº«ä¸»æ˜Ÿ"]:
        v = obj.get(key)
        if v:
            bi["èº«ä¸»"] = _clean(str(v))
            break
    
    for key in ["é˜³å†æ—¥æœŸ", "é˜³å†", "å…¬å†"]:
        v = obj.get(key)
        if v:
            bi["é˜³å†æ—¥æœŸ"] = _clean(str(v))
            break
    
    for key in ["çœŸå¤ªé˜³æ—¶", "çœŸå¤ªé™½æ™‚"]:
        v = obj.get(key)
        if v:
            bi["çœŸå¤ªé˜³æ—¶"] = _clean(str(v))
            break
    
    for key in ["å‘½å±€", "å±€æ•°"]:
        v = obj.get(key)
        if v:
            bi["å‘½å±€"] = _clean(str(v))
            break

    print(f"[Ziwei Parser Debug] æ‰å¹³æ ¼å¼æå–ç»“æœ: {bi}")
    return out


# ========== çº¯æ–‡æœ¬è§£æï¼ˆå…¼å®¹ç”¨æˆ·ç›´æ¥ç²˜è´´"å®«å—æ–‡å­—ç‰ˆ"ï¼‰ ==========

# åŸºæœ¬ä¿¡æ¯æ­£åˆ™
_P_BIRTH = re.compile(r"å‡ºç”Ÿæ—¶é—´[:ï¼š]\s*([0-9\-\/å¹´æœˆæ—¥\.]+[ T]?[0-9:\.æ—¶åˆ†ç§’]*)", re.I)
_P_TRUE = re.compile(r"çœŸå¤ªé˜³æ—¶[:ï¼š]\s*([0-9\-\/å¹´æœˆæ—¥\.]+[ T]?[0-9:\.æ—¶åˆ†ç§’]*)", re.I)
_P_SOLAR = re.compile(r"(é˜³å†|å…¬å†)[:ï¼š]\s*([0-9\-\/å¹´æœˆæ—¥\.]+)", re.I)
_P_LUNAR = re.compile(r"(é˜´å†|å†œå†|é™°æ›†)[:ï¼š]\s*([^\n\r]+)", re.I)
_P_SEX = re.compile(r"æ€§åˆ«[:ï¼š]\s*([ç”·å¥³é˜´é˜³])", re.I)
_P_MZ = re.compile(r"å‘½ä¸»[:ï¼š]\s*([^\sï¼Œ,\n\r]+)", re.I)
_P_SZ = re.compile(r"èº«ä¸»[:ï¼š]\s*([^\sï¼Œ,\n\r]+)", re.I)
_P_JU = re.compile(r"(å‘½å±€|å±€æ•°|å±€)[:ï¼š]\s*([^\sï¼Œ,\n\r]+)", re.I)

# å®«å—æ­£åˆ™
# åŒ¹é… "å‘½å®«"ã€"å¤«å¦»å®«" ç­‰
_P_PALACE_HEAD = re.compile(r"^([{}])å®«".format("".join(PALACES)), re.M)
_P_MAINLINE = re.compile(r"ä¸»æ˜Ÿ[:ï¼š]\s*([^\n\r]+)", re.I)
_P_SUBLINE = re.compile(r"(å‰¯æ›œ|è¾…æ˜Ÿ|æ‚æ›œ|å°æ˜Ÿ)[:ï¼š]\s*([^\n\r]+)", re.I)


def parse_wenmo_plain_text(text: str) -> Dict[str, Any]:
    """
    ä¸¥æ ¼ä»æ™®é€šæ–‡å­—ç‰ˆå‘½ç›˜ä¸­æŠ½å–æ•°æ®
    å°½åŠ›è€Œä¸ºï¼Œä¸æ¨æ–­ç¼ºå¤±ä¿¡æ¯
    """
    out = _empty_v11()
    t = text or ""

    # æå– basic_info
    m = _P_BIRTH.search(t)
    if m:
        out["basic_info"]["é˜³å†æ—¥æœŸ"] = _clean(m.group(1))
    
    m = _P_TRUE.search(t)
    if m:
        out["basic_info"]["çœŸå¤ªé˜³æ—¶"] = _clean(m.group(1))
    
    m = _P_SOLAR.search(t)
    if m:
        out["basic_info"]["é˜³å†æ—¥æœŸ"] = _clean(m.group(2))
    
    m = _P_LUNAR.search(t)
    if m:
        out["basic_info"]["é˜´å†æ—¥æœŸ"] = _clean(m.group(2))
    
    m = _P_SEX.search(t)
    if m:
        out["basic_info"]["æ€§åˆ«"] = _clean(m.group(1))
    
    m = _P_MZ.search(t)
    if m:
        out["basic_info"]["å‘½ä¸»"] = _clean(m.group(1))
    
    m = _P_SZ.search(t)
    if m:
        out["basic_info"]["èº«ä¸»"] = _clean(m.group(1))
    
    m = _P_JU.search(t)
    if m:
        out["basic_info"]["å‘½å±€"] = _clean(m.group(2))

    # æå–å®«ä½æ˜Ÿæ›œï¼ˆé€æ®µæ‰¾"XXå®«"æŠ¬å¤´ï¼Œå¾€ä¸‹æ”¶é›†åˆ°ä¸‹ä¸€ä¸ªå®«ä½æŠ¬å¤´ä¸ºæ­¢ï¼‰
    star_map = out["star_map"]
    
    # åœ¨æ–‡æœ¬ä¸­å®šä½æ¯ä¸ªå®«ä½çš„å¼€å§‹ä½ç½®
    heads = []
    for p in PALACES:
        for m in re.finditer(r"^{}å®«".format(p), t, flags=re.M):
            heads.append((m.start(), p))
    heads.sort()
    
    # é€ä¸ªå®«ä½æå–æ˜Ÿæ›œ
    for idx, (pos, palace) in enumerate(heads):
        # ç¡®å®šè¿™ä¸ªå®«ä½çš„æ–‡æœ¬å—èŒƒå›´
        end = heads[idx + 1][0] if idx + 1 < len(heads) else len(t)
        block = t[pos:end]
        
        bucket: List[str] = []
        
        # æå–ä¸»æ˜Ÿ
        m = _P_MAINLINE.search(block)
        if m:
            stars_str = _clean(m.group(1))
            bucket += re.split(r'[ï¼Œ,ã€\s]+', stars_str)
        
        # æå–å‰¯æ›œã€å°æ˜Ÿç­‰
        for m in _P_SUBLINE.finditer(block):
            stars_str = _clean(m.group(2))
            bucket += re.split(r'[ï¼Œ,ã€\s]+', stars_str)
        
        # è¿‡æ»¤æ‰æ— æ•ˆæ¡ç›®
        star_map[palace] = [
            x for x in bucket 
            if x and x not in ["ä¸»æ˜Ÿ", "å‰¯æ›œ", "å°æ˜Ÿ", "è¾…æ˜Ÿ", "æ‚æ›œ", "ï¼š", ":"]
        ]

    return out


def parse_wenmo_ai_file(file_bytes: bytes, filename: str) -> Dict[str, Any]:
    """
    ç»Ÿä¸€å…¥å£ï¼šè§£ææ–‡å¢¨å¤©æœº AI åˆ†æç‰ˆæ–‡ä»¶
    - è‹¥ä¸º .jsonï¼šæŒ‰ JSON æ ¼å¼è§£æ
    - å¦åˆ™ï¼šæŒ‰çº¯æ–‡æœ¬æ ¼å¼è§£æ
    éƒ½ä¸åšæ¨æ–­ï¼Œä»…åšè§„åˆ™æå–
    """
    name = (filename or "").lower()
    
    # å°è¯• JSON è§£æ
    try:
        if name.endswith(".json") or name.endswith(".txt"):
            text = file_bytes.decode("utf-8", errors="ignore")
            
            # å…ˆå°è¯• JSON
            try:
                obj = json.loads(text)
                result = parse_wenmo_ai_json(obj)
                
                # è¾“å‡ºå®Œæ•´ JSON ç»“æ„æ—¥å¿—
                print("[ZiweiJSON v1.1] å®Œæ•´ç»“æ„åŒ…å«ä»¥ä¸‹å­—æ®µ:")
                print(f"  - meta: {list(result['meta'].keys())}")
                print(f"  - basic_info: {list(result['basic_info'].keys())}")
                print(f"  - star_map: {len(result['star_map'])} ä¸ªå®«ä½")
                print(f"  - transformations: {list(result['transformations'].keys())}")
                print(f"  - tags: {list(result['tags'].keys())}")
                print(f"[ZiweiJSON v1.1] å®Œæ•´æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
                
                return result
            except json.JSONDecodeError:
                # JSON è§£æå¤±è´¥ï¼ŒæŒ‰çº¯æ–‡æœ¬å¤„ç†
                if TXT_PATCH_AVAILABLE:
                    print("[Ziwei Parser] ğŸ“ å¯ç”¨ TXT è¡¥ä¸è§£ææ–‡å¢¨å¤©æœºå‘½ç›˜...")
                    print(f"[TXT Debug] åŸå§‹æ–‡æœ¬å‰500å­—ç¬¦:\n{text[:500]}")
                    txt_data = parse_wenmo_txt_to_json(text)
                    print(f"[TXT Debug] è§£æè¿”å›çš„ star_map å®«ä½æ•°: {len(txt_data.get('star_map', {}))}")
                    print(f"[TXT Debug] å‘½å®«åŸå§‹æ•°æ®: {txt_data.get('star_map', {}).get('å‘½å®«', 'NOT_FOUND')}")
                    # è½¬æ¢ä¸ºæ ‡å‡† v1.1 æ ¼å¼
                    result = _empty_v11()
                    result["basic_info"].update(txt_data.get("basic_info", {}))
                    result["star_map"] = txt_data.get("star_map", {})
                    result["transformations"] = txt_data.get("transformations", {})
                    print(f"[ZiweiText v1.1] TXT è¡¥ä¸è§£æå®Œæˆï¼Œå‘½å®«: {result['star_map'].get('å‘½å®«', {})}")
                    print(f"[ZiweiText v1.1] å®Œæ•´æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
                    return result
                else:
                    result = parse_wenmo_plain_text(text)
                    print("[ZiweiText v1.1] çº¯æ–‡æœ¬è§£æå®Œæˆï¼ˆæ—§ç‰ˆï¼‰")
                    print(f"[ZiweiText v1.1] å®Œæ•´æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
                    return result
    except Exception as e:
        print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥: {e}")
    
    # å…¶ä»–æƒ…å†µï¼šæŒ‰çº¯æ–‡æœ¬è§£æ
    text = file_bytes.decode("utf-8", errors="ignore")
    if TXT_PATCH_AVAILABLE:
        print("[Ziwei Parser] ğŸ“ å¯ç”¨ TXT è¡¥ä¸ï¼ˆfallback è·¯å¾„ï¼‰...")
        txt_data = parse_wenmo_txt_to_json(text)
        result = _empty_v11()
        result["basic_info"].update(txt_data.get("basic_info", {}))
        result["star_map"] = txt_data.get("star_map", {})
        result["transformations"] = txt_data.get("transformations", {})
        print("[ZiweiText v1.1] é»˜è®¤çº¯æ–‡æœ¬è§£æå®Œæˆï¼ˆTXT è¡¥ä¸ï¼‰")
        return result
    else:
        result = parse_wenmo_plain_text(text)
        print("[ZiweiText v1.1] é»˜è®¤çº¯æ–‡æœ¬è§£æå®Œæˆï¼ˆæ—§ç‰ˆï¼‰")
        return result


def validate_wenmo_file(data: Dict[str, Any]) -> tuple[bool, str]:
    """
    éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸ºåˆæ³•çš„ç´«å¾®å‘½ç›˜æ•°æ®ï¼ˆå…¼å®¹å¤šç‰ˆæœ¬ï¼‰
    è¿”å›: (is_valid, error_message)
    """
    # âœ… ä¿®æ”¹ï¼šæ”¯æŒå¤šç§ç‰ˆæœ¬æ ¼å¼ï¼ˆAIç‰ˆã€æ‰‹å·¥ç‰ˆã€manualç­‰ï¼‰
    parser_version = data.get("meta", {}).get("parser_version", "")
    if not parser_version or not parser_version.startswith(("wenmo", "ZiweiAI", "manual")):
        print(f"[Ziwei DEBUG] âš ï¸ éæ ‡å‡†ç‰ˆæœ¬æ•°æ®ï¼ˆ{parser_version}ï¼‰ï¼Œç»§ç»­å…¼å®¹æ¨¡å¼")
        # ä¸å†ä¸¥æ ¼æ‹’ç»ï¼Œå…è®¸ç»§ç»­å¤„ç†
    
    # æ£€æŸ¥ source æ ‡è¯†ï¼ˆæ”¾å®½æ£€æŸ¥ï¼‰
    source = data.get("meta", {}).get("source", "")
    if source and "æ–‡å¢¨" not in source and "WenMo" not in source and "wenmo" not in source.lower() and "manual" not in source.lower():
        print(f"[Ziwei DEBUG] âš ï¸ éæ–‡å¢¨å¤©æœºæ¥æºï¼ˆ{source}ï¼‰ï¼Œç»§ç»­å…¼å®¹æ¨¡å¼")
    
    return True, ""
