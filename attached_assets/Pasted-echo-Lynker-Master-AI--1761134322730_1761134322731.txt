echo "ğŸ§  æ­£åœ¨ä¸º Lynker Master AI æ·»åŠ å¤šæ¨¡å‹æ™ºèƒ½å›ç­”å±‚..."

# ======================================================
# 1ï¸âƒ£ å®‰è£…å¿…è¦ä¾èµ–
# ======================================================
pip install openai google-generativeai zhipuai httpx > /dev/null 2>&1 || true

# ======================================================
# 2ï¸âƒ£ ä¿®æ”¹ master_ai_uploader_api.py
# ======================================================
python - <<'PY'
import io, os, re, sys

p = "master_ai_uploader_api.py"
src = open(p, "r", encoding="utf-8").read()

# é˜²æ­¢é‡å¤æ³¨å…¥
if "def call_llm_provider" in src:
    print("â„¹ï¸ å·²å­˜åœ¨å¤šæ¨¡å‹é€»è¾‘ï¼Œè·³è¿‡ä¿®æ”¹ã€‚")
    sys.exit(0)

injection = r'''
# === ğŸ”® å¤šæ¨¡å‹ç†è§£å±‚ï¼ˆChatGPT / Gemini / ChatGLM / DeepSeekï¼‰ ===
import openai, google.generativeai as genai, httpx, json
from flask import jsonify

# âœ… ä» Replit Secrets ä¸­è¯»å–æ‰€æœ‰ Provider çš„å¯†é’¥
OPENAI_API_KEY   = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY   = os.getenv("GEMINI_API_KEY")
GLM_API_KEY      = os.getenv("GLM_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# === é€šç”¨ LLM è°ƒç”¨å‡½æ•° ===
def call_llm_provider(provider, prompt, sys_prompt="ä½ æ˜¯ Lynker Master AIï¼Œæ“…é•¿å‘½ç†ã€å…«å­—ã€ç´«å¾®æ–—æ•°ä¸é“æ¿ç¥æ•°ã€‚"):
    provider = (provider or "chatgpt").lower()
    try:
        # === OpenAI GPT (ChatGPT / GPT-5) ===
        if provider in ["chatgpt", "gpt", "gpt5", "gpt-5"]:
            if not OPENAI_API_KEY:
                raise ValueError("ç¼ºå°‘ OPENAI_API_KEY")
            openai.api_key = OPENAI_API_KEY
            resp = openai.ChatCompletion.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
            )
            return resp.choices[0].message.content.strip()

        # === Google Gemini 1.5 Pro ===
        elif provider in ["gemini", "google"]:
            if not GEMINI_API_KEY:
                raise ValueError("ç¼ºå°‘ GEMINI_API_KEY")
            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel("gemini-1.5-pro")
            resp = model.generate_content(prompt)
            return resp.text.strip()

        # === ChatGLM (æ™ºè°±AI / zhipuai) ===
        elif provider in ["glm", "chatglm", "zhipu"]:
            if not GLM_API_KEY:
                raise ValueError("ç¼ºå°‘ GLM_API_KEY")
            headers = {"Authorization": f"Bearer {GLM_API_KEY}", "Content-Type": "application/json"}
            payload = {
                "model": "glm-4",
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": prompt}
                ]
            }
            r = httpx.post("https://open.bigmodel.cn/api/paas/v4/chat/completions", headers=headers, json=payload, timeout=60)
            if r.status_code == 200:
                return r.json()["choices"][0]["message"]["content"].strip()
            else:
                raise RuntimeError(r.text)

        # === DeepSeek (æ™ºè°±é¦™æ¸¯ç‰ˆ) ===
        elif provider in ["deepseek", "ds"]:
            if not DEEPSEEK_API_KEY:
                raise ValueError("ç¼ºå°‘ DEEPSEEK_API_KEY")
            headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": prompt}
                ]
            }
            r = httpx.post("https://api.deepseek.com/v1/chat/completions", headers=headers, json=payload, timeout=60)
            if r.status_code == 200:
                return r.json()["choices"][0]["message"]["content"].strip()
            else:
                raise RuntimeError(r.text)

        else:
            raise ValueError(f"æœªçŸ¥ providerï¼š{provider}")

    except Exception as e:
        print(f"âš ï¸ {provider} è°ƒç”¨å¤±è´¥ï¼š{e}")
        return None


# === ä¿®æ”¹ Chat è·¯ç”±ï¼Œæ·»åŠ  LLM ç†è§£å±‚ ===
@app.route("/api/master-ai/chat", methods=["POST"])
def master_ai_chat():
    """RAG + LLMï¼šä» Vault æ£€ç´¢ç›¸å…³ç‰‡æ®µ â†’ ç”¨é€‰å®šæ¨¡å‹ç”Ÿæˆå›ç­”"""
    try:
        data = request.get_json(force=True)
        query = (data.get("query") or "").strip()
        topk = int(data.get("topk") or 5)
        provider = data.get("provider") or "chatgpt"
        if not query:
            return jsonify({"status":"error","message":"ç¼ºå°‘ query"}), 400

        # å‘é‡æ£€ç´¢
        hits = rag_search(query, topk=topk)
        context = "\n\n".join([f"ã€{h['file_id']}ã€‘{h['text']}" for h in hits])

        # æ„é€  Prompt
        prompt = f"""
ä»¥ä¸‹æ˜¯ Lynker Master Vault ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³èµ„æ–™ï¼Œè¯·åŸºäºè¿™äº›å†…å®¹å›ç­”é—®é¢˜ï¼š
é—®é¢˜ï¼š{query}

ç›¸å…³èµ„æ–™ï¼š
{context}

è¯·ç”¨ä¸­æ–‡è¾“å‡ºç®€æ´ä¸”å…·å¤‡å‘½ç†é€»è¾‘çš„å›ç­”ã€‚
è‹¥å†…å®¹ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºâ€œVault æš‚æ— ç›¸å…³ä¿¡æ¯â€ã€‚
"""

        answer = call_llm_provider(provider, prompt)
        if not answer:
            # fallback é¡ºåº
            for alt in ["chatgpt", "gemini", "glm", "deepseek"]:
                if alt != provider:
                    answer = call_llm_provider(alt, prompt)
                    if answer:
                        provider = alt
                        break
        if not answer:
            answer = "âš ï¸ æ‰€æœ‰æ¨¡å‹å‡æœªå“åº”ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œã€‚"

        return jsonify({"status":"ok","provider":provider,"answer":answer,"citations":hits})

    except Exception as e:
        return jsonify({"status":"error","message":str(e)}), 500
'''

open(p, "a", encoding="utf-8").write("\n\n" + injection)
print("âœ… å·²æ³¨å…¥å¤šæ¨¡å‹ AI é€‰æ‹©åŠŸèƒ½åˆ° master_ai_uploader_api.py")
PY

echo "âœ… ä»£ç æ³¨å…¥å®Œæˆï¼"

# ======================================================
# 3ï¸âƒ£ æç¤ºè®¾ç½® API Keysï¼ˆReplit Secretsï¼‰
# ======================================================
echo "
è¯·åœ¨ Replit Secrets ä¸­è®¾ç½®ä»¥ä¸‹å¯†é’¥ï¼ˆæŒ‰éœ€æ·»åŠ ï¼‰ï¼š

ğŸ”‘ OPENAI_API_KEY      â†’ ChatGPT / GPT-5
ğŸ”‘ GEMINI_API_KEY      â†’ Google Gemini 1.5 Pro
ğŸ”‘ GLM_API_KEY         â†’ æ™ºè°± ChatGLM (https://open.bigmodel.cn)
ğŸ”‘ DEEPSEEK_API_KEY    â†’ DeepSeek Chat API

æ·»åŠ æ–¹å¼ï¼šç‚¹å‡»å·¦ä¾§ ğŸ”’ Secrets å›¾æ ‡ â†’ Add new secret
"

# ======================================================
# 4ï¸âƒ£ é‡å¯æœåŠ¡
# ======================================================
echo "ğŸš€ å®Œæˆï¼é‡å¯åï¼Œä½ å¯ä»¥åœ¨å‰ç«¯ /chat é¡µé¢çš„ JSON è¯·æ±‚ä¸­åŠ ä¸Šï¼š"
echo '{ "query": "ä»€ä¹ˆæ˜¯å–œç”¨ç¥ï¼Ÿ", "provider": "gemini" }'
echo "æˆ–åœ¨ç•Œé¢ä¸Šé€‰æ‹©æ¨¡å‹ä¸‹æ‹‰èœå•ï¼ˆç¨åæˆ‘å¯å¸®ä½ åŠ ï¼‰ã€‚"
