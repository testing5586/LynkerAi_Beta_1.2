#!/usr/bin/env python3
"""
Master AI Memory Bridge - ä¸Šä¼ æ—¥å¿—åˆ°å­AIè®°å¿†ç³»ç»Ÿçš„æ¡¥æ¥æ¨¡å—
è‡ªåŠ¨å°†æ–‡ä»¶ä¸Šä¼ è®°å½•åŒæ­¥åˆ° child_ai_memory è¡¨ï¼Œå®ç°çŸ¥è¯†åº“çš„"è‡ªå­¦ä¹ è®°å¿†"
"""

import json
import os
from datetime import datetime
from supabase_init import get_supabase

LOG_FILE = "upload_log.json"
LOCAL_BACKUP = "child_ai_memory_backup.json"
SYNC_STATE_FILE = "memory_sync_state.json"

def load_sync_state():
    """è¯»å–åŒæ­¥çŠ¶æ€ï¼Œè¿”å›å·²åŒæ­¥çš„è®°å½•é›†åˆï¼ˆä»…ä¾èµ–å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰"""
    if not os.path.exists(SYNC_STATE_FILE):
        return set()
    
    try:
        with open(SYNC_STATE_FILE, 'r', encoding='utf-8') as f:
            state = json.load(f)
            return set(state.get("synced_entries", []))
    except:
        return set()

def save_sync_state(synced_entries):
    """ä¿å­˜åŒæ­¥çŠ¶æ€ï¼ˆä»…ä¿å­˜å”¯ä¸€æ ‡è¯†ç¬¦é›†åˆï¼‰"""
    state = {
        "synced_entries": list(synced_entries),
        "total_synced": len(synced_entries),
        "last_update": datetime.now().isoformat()
    }
    with open(SYNC_STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def bridge_new_uploads_to_memory(limit=3):
    """
    å°†æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶åŒæ­¥åˆ°å­AIè®°å¿†ç³»ç»Ÿï¼ˆå¹‚ç­‰æ€§ä¿è¯ï¼‰
    
    Args:
        limit: åŒæ­¥æœ€è¿‘Næ¡è®°å½•ï¼ˆé»˜è®¤3æ¡ï¼‰
    
    Returns:
        dict: åŒæ­¥ç»“æœç»Ÿè®¡
    """
    
    # è·å– Supabase å®¢æˆ·ç«¯
    supabase = get_supabase()
    if not supabase:
        print("âš ï¸ Supabase æœªé…ç½®ï¼Œè·³è¿‡è®°å¿†åŒæ­¥")
        return {"success": False, "error": "Supabase not configured"}
    
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
    if not os.path.exists(LOG_FILE):
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° upload_log.json")
        return {"success": False, "error": "Log file not found"}
    
    # è¯»å–ä¸Šä¼ æ—¥å¿—
    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            logs = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"âš ï¸ è¯»å–æ—¥å¿—å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}
    
    if not logs:
        print("âš ï¸ æ²¡æœ‰å¯åŒæ­¥çš„æ—¥å¿—è®°å½•")
        return {"success": False, "error": "No logs to sync"}
    
    # è¯»å–åŒæ­¥çŠ¶æ€ï¼ˆå·²åŒæ­¥çš„å”¯ä¸€æ ‡è¯†ç¬¦é›†åˆï¼‰
    synced_entries = load_sync_state()
    
    # åªå¤„ç†æœªåŒæ­¥çš„æ–°è®°å½•ï¼ˆä»…ä¾èµ–å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
    new_entries = []
    for entry in logs:
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆfilename + timestampï¼‰
        entry_id = f"{entry.get('filename')}_{entry.get('timestamp')}"
        if entry_id not in synced_entries:
            new_entries.append((entry, entry_id))
    
    if not new_entries:
        print("âœ… æ‰€æœ‰è®°å½•å·²åŒæ­¥ï¼Œæ— éœ€é‡å¤å¤„ç†")
        return {"success": True, "synced": 0, "failed": 0, "total": 0, "skipped": len(logs)}
    
    synced_count = 0
    failed_count = 0
    memories = []
    
    for entry, entry_id in new_entries:
        filename = entry.get("filename", "unknown")
        summary = entry.get("summary", "")
        category = entry.get("category", "uncategorized")
        uploaded_by = entry.get("uploaded_by", "unknown")
        timestamp = entry.get("timestamp", datetime.now().isoformat())
        
        # æ„å»ºè®°å¿†è®°å½•ï¼ˆé¿å… Supabase schema cache é—®é¢˜ï¼‰
        memory = {
            "user_id": uploaded_by,
            "partner_id": f"doc_{filename}",  # ä»¥æ–‡ä»¶åä½œè®°å¿†å¯¹è±¡æ ‡è¯†
            "summary": summary[:500] if summary else f"æ–‡æ¡£: {filename}",  # é™åˆ¶æ‘˜è¦é•¿åº¦
            "tags": [category, "document", "vault"],
            "similarity": 0.95,  # æ–‡æ¡£ä¸Šä¼ é»˜è®¤é«˜ç›¸ä¼¼åº¦
            "interaction_count": 1,
            "last_interaction": timestamp
        }
        
        try:
            # æ’å…¥åˆ° Supabase
            result = supabase.table("child_ai_memory").insert(memory).execute()
            print(f"ğŸ’¾ å·²åŒæ­¥è‡³å­AIè®°å¿†: {filename}")
            synced_count += 1
            memories.append(memory)
            
            # æ›´æ–°åŒæ­¥çŠ¶æ€ï¼ˆæ·»åŠ åˆ°å·²åŒæ­¥é›†åˆï¼‰
            synced_entries.add(entry_id)
            
        except Exception as e:
            print(f"âš ï¸ åŒæ­¥å¤±è´¥ {filename}: {e}")
            failed_count += 1
    
    # ä¿å­˜æœ¬åœ°å¤‡ä»½
    try:
        backup_data = {
            "last_sync": datetime.now().isoformat(),
            "total_synced": synced_count,
            "memories": memories
        }
        
        # è¯»å–ç°æœ‰å¤‡ä»½
        existing_backup = []
        if os.path.exists(LOCAL_BACKUP):
            try:
                with open(LOCAL_BACKUP, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    existing_backup = existing_data.get("memories", [])
            except:
                pass
        
        # åˆå¹¶å¹¶ä¿å­˜
        all_memories = existing_backup + memories
        backup_data["memories"] = all_memories[-100:]  # åªä¿ç•™æœ€è¿‘100æ¡
        
        with open(LOCAL_BACKUP, 'w', encoding='utf-8') as f:
            json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"âš ï¸ æœ¬åœ°å¤‡ä»½å¤±è´¥: {e}")
    
    # ä¿å­˜åŒæ­¥çŠ¶æ€ï¼ˆé˜²æ­¢é‡å¤åŒæ­¥ï¼‰- å³ä½¿æœ‰å¤±è´¥ä¹Ÿè¦ä¿å­˜
    save_sync_state(synced_entries)
    
    # è¿”å›ç»Ÿè®¡ç»“æœ
    result = {
        "success": True,
        "synced": synced_count,
        "failed": failed_count,
        "total": len(new_entries)
    }
    
    print(f"âœ… å…±åŒæ­¥ {synced_count} æ¡æ–°è®°å¿†ï¼ˆå¤±è´¥ {failed_count} æ¡ï¼‰")
    return result

def get_memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    supabase = get_supabase()
    if not supabase:
        return {"error": "Supabase not configured"}
    
    try:
        # æŸ¥è¯¢è®°å¿†æ€»æ•°
        result = supabase.table("child_ai_memory").select("*", count="exact").execute()
        total = result.count if hasattr(result, 'count') else len(result.data)
        
        # æŒ‰ç”¨æˆ·åˆ†ç»„ç»Ÿè®¡
        by_user = {}
        for memory in result.data:
            user = memory.get("user_id", "unknown")
            by_user[user] = by_user.get(user, 0) + 1
        
        return {
            "total_memories": total,
            "by_user": by_user,
            "recent": result.data[:5] if result.data else []
        }
        
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§  Master AI Memory Bridge")
    print("=" * 60)
    
    # æ‰§è¡ŒåŒæ­¥
    result = bridge_new_uploads_to_memory()
    
    print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    stats = get_memory_stats()
    if "error" not in stats:
        print(f"   æ€»è®°å¿†æ•°: {stats.get('total_memories', 0)}")
        print(f"   æŒ‰ç”¨æˆ·: {stats.get('by_user', {})}")
    else:
        print(f"   âš ï¸ {stats['error']}")
