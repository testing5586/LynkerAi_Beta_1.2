"""
Group Leader æ¨¡å—
Lynker Engine v2.0
è¿æ¥å±‚ï¼šChild AI â†’ Group Leader â†’ Master AI
åŠŸèƒ½ï¼š
- æ”¶é›†å„ Child AI è¾“å‡º
- æ ¼å¼åŒ– / åˆå¹¶
- ä¼ é€’ç»™ Master AI è¿›è¡Œæ·±åº¦æ¨ç†
"""

import datetime
import json
import sys
import os
try:
    from .master_ai import run_master_ai
except ImportError:
    from lynker_engine.core.master_ai import run_master_ai

# Set console encoding for Windows
if sys.platform == 'win32':
    os.system('chcp 65001 >nul')
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# ========== ğŸ”¹ å·¥å…·å‡½æ•° ==========
def safe_log(msg):
    ts = datetime.datetime.now().strftime("%H:%M:%S")
    print(f"[{ts}] GroupLeader> {msg}")

def safe_json(obj):
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except:
        return str(obj)

# ========== ğŸ”¹ ä¸»å‡½æ•°å…¥å£ ==========
def run_group_leader(task_topic, child_outputs):
    """
    task_topic: str - ä»»åŠ¡ä¸»é¢˜ï¼Œä¾‹å¦‚ "å¯¹ç…§åˆ†æï¼šå¤©åºœ vs æ­¦æ›²"
    child_outputs: dict - å­ AI çš„è¾“å‡ºåˆé›†ï¼Œä¾‹å¦‚ï¼š
    {
      "bazi_child": {...},
      "ziwei_child": {...},
      "tarot_child": {...}
    }
    """

    safe_log(f"æ¥æ”¶åˆ°ä»»åŠ¡: {task_topic}")
    safe_log(f"å­ AI è¾“å‡ºæ‘˜è¦: {list(child_outputs.keys())}")

    # Step 1ï¸âƒ£: æ•°æ®æ¸…æ´—
    normalized = normalize_child_outputs(child_outputs)

    # Step 2ï¸âƒ£: ç”Ÿæˆåè°ƒæŠ¥å‘Š
    notes = summarize_alignment(normalized)

    # Step 3ï¸âƒ£: æ‰“åŒ…ä»»åŠ¡ â†’ äº¤ç»™ Master AI
    payload = {
        "topic": task_topic,
        "bazi_result": normalized.get("bazi_child"),
        "ziwei_result": normalized.get("ziwei_child"),
        "tarot_result": normalized.get("tarot_child"),
        "group_notes": notes
    }

    safe_log("å·²æ‰“åŒ…ä»»åŠ¡ï¼Œä¼ é€’ç»™ Master AI ...")
    master_output = run_master_ai(payload)

    # Step 4ï¸âƒ£: è¾“å‡ºæœ€ç»ˆç»“æœ
    safe_log("Master AI å·²è¿”å›ç»“æœ âœ…")
    return {
        "group_notes": notes,
        "master_result": master_output
    }


# ========== ğŸ”¹ è¾…åŠ© 1ï¼šç»Ÿä¸€å­ AI è¾“å‡ºæ ¼å¼ ==========
def normalize_child_outputs(outputs):
    """
    å°†ä¸åŒå­ AI çš„è¾“å‡ºæ ‡å‡†åŒ–ä¸ºç»Ÿä¸€ JSON æ ¼å¼
    """
    normalized = {}
    for name, data in outputs.items():
        if not data:
            continue
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except:
                data = {"summary": data}
        normalized[name] = {
            "birth_time_confidence": data.get("birth_time_confidence", "æœªçŸ¥"),
            "key_supporting_evidence": data.get("key_supporting_evidence", []),
            "key_conflicts": data.get("key_conflicts", []),
            "summary": data.get("summary", "æ— æ‘˜è¦")
        }
    return normalized


# ========== ğŸ”¹ è¾…åŠ© 2ï¼šç”Ÿæˆåè°ƒæŠ¥å‘Š ==========
def summarize_alignment(normalized):
    """
    æ±‡æ€»ä¸åŒå‘½ç›˜éªŒè¯ç»“æœçš„æ€»ä½“è¶‹åŠ¿
    """
    notes = []
    for name, result in normalized.items():
        conf = result.get("birth_time_confidence", "æœªçŸ¥")
        summary = result.get("summary", "")
        notes.append(f"{name} å¯ä¿¡åº¦ï¼š{conf} â†’ {summary}")
    if not notes:
        return "æš‚æ— å­ AI è¾“å‡ºã€‚"
    return " | ".join(notes)


# ========== ğŸ”¹ æµ‹è¯•å…¥å£ ==========
if __name__ == "__main__":
    # æ¨¡æ‹Ÿä¸¤ä¸ªå­ AI è¾“å‡º
    child_outputs = {
        "bazi_child": {
            "birth_time_confidence": "é«˜",
            "key_supporting_evidence": ["äº‹ä¸šçº¿ä¸çœŸå®ç»å†å»åˆ"],
            "key_conflicts": ["å©šæœŸç•¥æ—©äºå‘½ç›˜æ˜¾ç¤º"],
            "summary": "æ•´ä½“å»åˆåº¦é«˜"
        },
        "ziwei_child": {
            "birth_time_confidence": "ä¸­é«˜",
            "key_supporting_evidence": ["å‘½å®«ä¸»æ˜Ÿç‰¹è´¨ä¸€è‡´"],
            "key_conflicts": [],
            "summary": "æ€»ä½“å‡†ç¡®"
        }
    }

    print(safe_json(run_group_leader("å¯¹ç…§åˆ†æï¼šå¤©åºœ vs æ­¦æ›²", child_outputs)))